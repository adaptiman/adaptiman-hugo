<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Audio Learning on Adaptiman</title>
    <link>https://people.tamu.edu/~adaptiman/tags/audio-learning/index.xml</link>
    <description>Recent content in Audio Learning on Adaptiman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 David Sean Sweeney</copyright>
    <atom:link href="/~adaptiman/tags/audio-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tactile TTS</title>
      <link>https://people.tamu.edu/~adaptiman/project/tactiletts/</link>
      <pubDate>Wed, 08 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://people.tamu.edu/~adaptiman/project/tactiletts/</guid>
      <description>&lt;p&gt;This is an introduction to TactileTTS, aniOS app written by David Sweeney that will be used to collect research data for my dissertation.&lt;/p&gt;

&lt;p&gt;TactileTTS is an iOS app that can be used to listen to audio texts such as excerpts from textbooks. The app allows the user to control the navigation of audio texts using swipe and tap gestures. Currently, the app can navigate by sentence and paragraph, and pause the text.&lt;/p&gt;

&lt;p&gt;The app also has the ability to send navigation information back to the researcher so that participants that use the app can contribute to the research.&lt;/p&gt;

&lt;p&gt;TactileTTS is designed to examine the effects of navigation on the comprehension of audio texts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
